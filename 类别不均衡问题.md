为什么特殊化处理：模型会照顾数量比较多的类别，而类别比较少的类别则不太会关心，而我们往往是关心类别比较少的类别。
### 解决方案

#### 1 从数据上解决
**问题**采样技术，怎样实现采样的呢？
既然正负例数据比重失调，那我们可以对原始数据集进行采样调整，使得调整后的数据集正负例数据接近，再进行训练。常见的采样方法包括欠采样和过采样两种。
1. 欠采样方法
欠采样是丢弃训练集的一些负例，那么经过调整后的数据集往往会远小于原始数据集。
但是欠采样往往要丢弃很多负例，可能会损失很多重要信息，因此我们在采样的时候，可以尽量选取比较重要的核心负例，丢弃没那么重要的负例。

2. 过采样方法
过采样是对正例进行扩充（数据增强），增加正例使得正反例数据接近，那么经过调整后的数据集往往会远大于原始数据集，增加了时间开销。
在NLP中我了解到的数据增强方法主要有：
1）加入噪声：在正例中加入一些噪声，比如随机删掉某些词，随机打乱词语顺序（在文本分类任务上或许可以，但是在一些有语序要求的任务上就不行），生成新的数据。
2）复述生成（paraphrasing）：属于seq2seq任务了，在问答系统有一个领域叫做问题复述，根据原始问题生成格式更好的问题，相当于修正不规范的问题，将新问题代替旧问题输入到问答系统中，我觉得的也算是一种数据增强方法了吧。
其实我自己平时并不用数据增强方法，因为我觉得文本和图像不一样，图像对某一些像素加入噪声，影响可能不是很大，但是在文本中一点小的改动可能就会带来很大的影响，你删掉的词很有可能就是比较重要的词，如果你删掉的词不重要那相当于删去停词，打乱顺序在很多任务上就更不行了，因为句子本身是有语序的，有上下文关系。文本生成倒是一种 我认为相对比较好的数据增强方式。

#### 2 从模型上着手解决
1. 对于二分类问题，可以调节sigmoid的阀值，例如类别少的正类可以将阀值调的低一点，设置一个超参数阀值
2. 修改损失函数
   - [focal loss](https://kexue.fm/archives/4733)
3. sample weight
4. class weight


[如何处理数据中的「类别不平衡」？](https://zhuanlan.zhihu.com/p/32940093)
[欠采样（undersampling）和过采样（oversampling）会对模型带来怎样的影响？](https://www.zhihu.com/question/269698662/answer/352279936)
[如何处理不平衡数据集的分类任务](https://zhuanlan.zhihu.com/p/67650069)
[分类问题-样本权重（sample_weight）和类别权重（class_weight](https://zhuanlan.zhihu.com/p/75679299)
[分类中解决类别不平衡问题](https://blog.csdn.net/program_developer/article/details/80287033)
