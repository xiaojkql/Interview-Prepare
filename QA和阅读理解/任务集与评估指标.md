Tasks:
四种类别: 完形填空(cloze test), 

完形填空
移除一篇文章中的某些词,然后基于文章的上下文对该词进行预测,预测词(词或者实体)有些任务给出了候选集,有些任务没有给出候选集。

核心要点: 要理解文章,所以任务的问题的解答必须要靠理解文章，而不是其他的方法

特征
- 预测词是否被替换
- 预测词是否有候选集(有就简化)
- 预测词是否多样性
- 是否自动产生
- 是否先总结，然后预测

主要作用:


构建数据集时需要考虑的问题:
- 文章与问题是否有比较长的重合词汇
- 预测词是否靠其他外部知识就可解答
- 是否短短的句子理解就可以解答预测出正确的词


该类型中常见的数据集
CNN & Daily Mail
author Hermann
|name|CNN|Daily Mail|
|articles|||
提取出的bullet points与原始文章的重复单词少。预测命名实体(entity)
命名实体全部用代号来指代,防止基于外部知识,而不是基于文章来完成.


CBT (The children's Book Test)
每个样本包含21条句子，第21条句子的某个词被移除，而其他20条句子保持不变作为上下文。
没有随机替换 可能引入外部知识，而不是理解文章来完成预测.
缺失的词更加多样了:实体，名词，动词，介词
有候选词集

LAMBADA
基于长篇章
预测词是目标居住的最后一个
难预测，必须要更广泛的上下文才能正确的预测出结果

Who-did-what
目标: 减少句法相似性,
聚焦于person name entity

CLOTH
人工构造的数据集
需要精通词，推理，语法才能完成
更少的无意义的和浅显的问题

CliCR
针对医疗领域的特定数据集
用了总结语
预测医疗领域的命名实体


## 多项选择(multiple choice)
根据文章选择一个最适合回答所提出问题的答案
答案不再仅仅只是一个词或者一个实体，更具有柔和性

MCTEST
500篇小说
每篇小说有四个问题
每个问题四个答案
使用小说是避免引入外部的一些知识 CBT,LAMBADA

RACE
收集于中国的考试中的题目
文章的类型更加多样化
回答问题需要更多的推理
诸如信息检索与词的共现简单的方法来解决该问题效果不会是很好


## 抽取式阅读理解数据集
SQUAD
- 基于维基百科
- 质量很好, 开创了阅读理解一个新任务

NewsQA
新的数据集
问题包含没有答案的问题

TriviaQA
制作过程的巧妙设计

DuoRC

## 自由答案式阅读理解
需要机器去跨句子进行推理和总结文章

## 数据集比较

