### 1 知识点总结
- 选择类别的样本少的精确率与召回率来评价模型(minority class)，可以选择其中一个指标，也可以用F值来进行平衡两者的重要性。
- 精确率和召回率是相对于二分类问题的，但是可以用于多分类问题。用于多分类问题时将每一个类别看成正类，而其他看成负类，从而输出每个类别的精确率和召回率，当然也可以将个类别的精确率，召回率来计算整个类别的精确率和召回率。两种计算方式宏(macro)和微(micro)平均(average)。宏平均好于微平均，因为宏平均更加考虑到了类别不平衡。
- PR曲线
- 精确率是基于预测的容易受到类别平衡的影响
- ROC曲线，AUC面积，不受样本类别不平衡的影响，即在训练时的评价指标与测试时的评价指标基本一致。
- 真正率(true positive rate) 假正率(false positive rate), 两者构成了ROC曲线，都是从零开始增加。表面含义就是要将正类很大部分都预测到，那么就要放宽要求，那么此时负类的一部分样本也很容易预测为正类了，导致了假正率增加。
- 拿到一系列样本预测分数，选择最好的threshold，求ROC曲线求AUC的面积
- ROC AUC 不受样本不均衡的影响，它反映的是模型的一种能力
- 为什么AUC和logloss比accuracy更常用呢？因为不需要确定阀值，使用AUC或者logloss可以避免把预测概率转换成类别。

### 2 常用评价指标
- 分类: 精确率、召回率、准确率、F值、ROC-AUC 、混淆矩阵、PRC

### 3 优秀的博客资源
[总结](http://sofasofa.io/forum_main_post.php?postid=1000605)
[知乎问答： 精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？](https://www.zhihu.com/question/30643044)
[机器学习分类模型评价指标详述](https://zhuanlan.zhihu.com/p/43405406)
[如何理解机器学习和统计中的AUC？](https://www.zhihu.com/question/39840928)
[在NLP当中，不同的评价指标，BLEU, METEOR, ROUGE和CIDEr的逻辑意义？](https://www.zhihu.com/question/304798594/answer/567383628)
