### 1 知识点总结
- 选择类别的样本少的精确率与召回率来评价模型(minority class)，可以选择其中一个指标，也可以用F值来进行平衡两者的重要性。
- 精确率和召回率是相对于二分类问题的，但是可以用于多分类问题。用于多分类问题时将每一个类别看成正类，而其他看成负类，从而输出每个类别的精确率和召回率，当然也可以将个类别的精确率，召回率来计算整个类别的精确率和召回率。两种计算方式宏(macro)和微(micro)平均(average)。宏平均好于微平均，因为宏平均更加考虑到了类别不平衡。
- PR曲线
- 精确率是基于预测的容易受到类别平衡的影响
- ROC曲线，AUC面积，不受样本类别不平衡的影响，即在训练时的评价指标与测试时的评价指标基本一致。
- ROC曲线，PR曲线不受特定阀值的影响，可以评价模型的整体性能---> 整体是指对正例和负例的分类能力
- Precision,Recall是受特定阀值的影响的，阀值取得不一样则评价指标的表现就不一样
- Precision是受样本分布的影响的。
- 真正率(true positive rate) 假正率(false positive rate), 两者构成了ROC曲线，都是从零开始增加。表面含义就是要将正类很大部分都预测到，那么就要放宽要求，那么此时负类的一部分样本也很容易预测为正类了，导致了假正率增加。
- 拿到一系列样本预测分数，选择最好的threshold，求ROC曲线求AUC的面积
- ROC AUC 不受样本不均衡的影响，它反映的是模型的一种能力。即我的模型已经学习好了，即具有分类的能力了，那么对于再次取样本无论是否类别平衡还是不平衡都会是同样的评价指标，评价不变性，反映的是模型的一种内在能力。而Precision会受到类别分布的影响而影响
- 为什么AUC和logloss比accuracy更常用呢？因为不需要确定阀值，使用AUC或者logloss可以避免把预测概率转换成类别。
- 所以这也是为什么在类别不平衡问题中用ROC和PR曲线来评估非常流行，因为它们不受特定阈值变化的影响，反映的是模型的整体预测能力
- AUC越大，自然排序能力越好，即分类器将越多的正例排在负例之前
- ROC兼顾正例和负例的权衡。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法
- ROC由于其鲁棒性会带来缺点，如果我们再次取得数据分布均匀，我们关心Prcision,则会造成错误判断。
- PR曲线的两个指标(Precision, Recall)都聚焦于正例。类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被广泛认为优于ROC曲线。
- 数据分布的变化应用场景：每个统计周期内的数据分布式不一样，则用ROC还是用PR来评价，具体要求具体来选择。

### 2 常用评价指标
- 分类: 精确率、召回率、准确率、F值、ROC-AUC 、混淆矩阵、PRC

### 3 优秀的博客资源
[总结](http://sofasofa.io/forum_main_post.php?postid=1000605)
[知乎问答： 精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？](https://www.zhihu.com/question/30643044)
[机器学习分类模型评价指标详述](https://zhuanlan.zhihu.com/p/43405406)
[如何理解机器学习和统计中的AUC？](https://www.zhihu.com/question/39840928)
[在NLP当中，不同的评价指标，BLEU, METEOR, ROUGE和CIDEr的逻辑意义？](https://www.zhihu.com/question/304798594/answer/567383628)
[类别不平衡的评价指标](https://www.cnblogs.com/massquantity/p/8550875.html)
[ROC PR曲线，优缺点，实验对比](https://www.cnblogs.com/massquantity/p/8592091.html)
[ROC绘制,AUC计算](https://www.cnblogs.com/sddai/p/8360089.html)
[AUC计算](https://blog.csdn.net/luo3300612/article/details/80367901)

### 4重要的总结
[二分类评判指标总结](https://towardsdatascience.com/the-ultimate-guide-to-binary-classification-metrics-c25c3627dd0a)
