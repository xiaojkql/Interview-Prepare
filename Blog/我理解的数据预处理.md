---
title: 我理解的数据预处理
categories:
- machine learning
- scikit-learn
tags:
- 数据预处理
date: 2019-03-22 13:00:00
---

# 1 Dataset transformations
主要用于对原始数据进行转换。
- 清理数据 clean (Preprocessing),做一些转换工作，都在单个特征以内。乘除转换，处理缺失值。
- 降维 reduce (Unsupervised dimensionality)
- 增维，低维到高维的映射 expand (Kernel approximation)
- 学习特征表示

# 2 清理数据(Preprocessing)


sklearn.preprocessing 包提供一些工具函数和工具类。

原因：学习算法在标准化的数据集上表现的更好。但是在含有异常点时，需要使用更稳健的标准化方法。

## 2.1
**让所有特征的均值为0，标准差为1，即均值标准差相等**

简单的数据转换：**减均值除标准差**转换成每个特征具有均值为0，方差为1的数据集。好处：各个特征同等重要，同时也是许多学习器所要求的数据格式。
```python
sklearn.preprocessing.scale(array) # 函数 只能一次
sklearn.preprocessing.StandardScaler() # 创建一个类能记忆mean var
- fit(X)
- transform(X)
```

## 2.2 转换到一个range

**转换到同一个数量级上，但是均值，方差未考虑**

通常转换到[0,1]范围内。

原因：
- 1 标准差小时，上面的转换不稳定。
- 2 可以让稀疏数据中的0得以保持。

```python
MinMaxScaler((a,b))  # 线性映射到[a,b]
MaxAbsScaler  # 直接除以最大值
```

## 2.3 特殊对待稀疏数据

一定要保持稀疏性。同行保持存储的一致，CSC,CSR。

## 2.4 特殊对待带有异常点的数据

使用，robust_scale,

scaling vs whitening

一个是缩小范围，一个是降低相关性。

## centering kernel matrics

当含有kernel的时候

# 3 非线性转换

即改变数据的分布，将数据转换到我们需要的分布。

有什么作用呢？

## 3.1 映射为均匀分布

用分位数信息进行数据转换

## 3.2 映射为高斯分布


# 4 Normalization

**使每一个样本具有1的norm**

在有点积或者其他kernel来度量两个样本之间的相似性的时候特别有用。but,why?

# 5 对类别数据进行编码



# 6 对连续数据进行离散化处理

**分包**


# 7 对缺失数据的处理

数据库的缺失数据会用blank,NaNs,或者其他占位符来代替缺失的数据。

```python
sklearn.SimpleImpiter()
```

# 产生多项式数据
