---
title: 我理解的分类问题的0-1损失函数
categories:
- machine learning
tags:
- machine learning
- 0-1损失
date: 2019-3-20 21:00:00
---
# 1 分类问题的描述
对于一个训练数据集$x=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}$，其中$y_i$的取值为多个类别中的一种，那么此时要训练学习一个分类函数$f(x)$对该训练数据集进行分类，那么该如何定义损失函数呢？很显然我们想分类的错误率越低越好，最好的情况就是0。所以当出现分类错误一次，我们记录一次，没有分类错误，就不记录。就引入0-1损失，即分类错了就将损失加1，没有分类错就不管。所以损失函数定义如下：
$$ Loss= \sum_{i=1}^{n}I(f(x_i)\ne y_i)\\
I(z)=1 \ if\ z>0 \ else \  1 \tag{1}$$
这是一个经验风险函数。  
# 2 分类问题的期望风险
特征向量$X$对应一个分布函数$D(X)$，输出值$y$对应着一个概率分布$D(y)$，两者的联合概率分布为$D(X,y)$，那么给定一个X用函数$f(x)$对y进行预测，此时期望风险为
$$ E_{~D(x,y)}[loss]=\int I(f(x)\ne y)p_{x,y} \tag{2}$$
因为
$$ p_{x,y}=p(y|x)p(x) \tag{3}$$
所以
$$ E_{~D(x,y)}[Loss]=\int I(f(x)\ne y)p(y|x)p(x) \tag{4}$$
因为在给定一个x的情况下，p(x)是固定的对E没有影响。所以，我们只考虑
$$ E_{~D(y|x)}[Loss] = \int I(f(x)\ne y)p(y|x) \tag{5}$$
那么给定x下y的分布为什么呢？  
现在我们假设给定x下，y的类别有猪、牛、马、羊，对应的概率为$\frac{1}{2},\frac{1}{8},\frac{1}{8},\frac{1}{4}$,那么此时我们的$f(x)$应该给出的标签是啥，才能使期望风险最小，  
当$f(x)=猪时$
$$ E_{~D(y|x)} = \frac{1}{8}+\frac{1}{8}+\frac{1}{4}=\frac{1}{2} \tag{6}$$
当$f(x)=牛时$
$$ E_{~D(y|x)} = \frac{1}{2}+\frac{1}{8}+\frac{1}{4}=\frac{7}{8} \tag{7}$$
当$f(x)=马时$
$$ E_{~D(y|x)} = \frac{1}{2}+\frac{1}{8}+\frac{1}{4}=\frac{7}{8} \tag{8}$$
当$f(x)=羊时$
$$ E_{~D(y|x)} = \frac{1}{2}+\frac{1}{8}+\frac{1}{8}=\frac{6}{8} \tag{9}$$
很显然是f(x)=猪时，期望风险最小，即选择了$P(y|x)$最大的那一个标签，即条件概率最大的那一个，对应着贝叶斯分类器。  
所以0,1损失函数最小对应着贝叶斯分类器，在贝叶斯准则下，是最好的。当0-1损失最小化时也即做了贝叶斯分类。  
0-1损失也是期望风险最小化的代理。
# 3 二分类分类问题的极大似然估计
当我们对后验概率$p(y|x)$假设为伯努利分布时即
$$ [Y|X] ~ Bernoulli(p(X)) $$
p(X)表示是参数X的函数，那么此时估计p用极大似然函数
