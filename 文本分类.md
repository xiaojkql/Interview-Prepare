[评价指标](https://zhuanlan.zhihu.com/p/69101372)

[Bert 文本分类](https://zhuanlan.zhihu.com/p/69389583)

[项目参考1](https://github.com/songyingxin/TextClassification-Pytorch)
[参考项目2](https://github.com/zenRRan/Sentiment-Analysis)
[达观杯 文本分类 10名](https://github.com/moneyDboat/data_grand)
[传统的一些方法 github](https://github.com/baiziyuandyufei/text_classification)

### 任务介绍

### 文本表示
- 语义粒度：是词表示还是字表示 还是两者都保留
- 文本长度：取一个合适的长度，超过截断，不足补0

### 词向量选择
word2vec, glove, fasttext, ELMO
将多个词向量进行融合：平均，拼接
词向量维度的选择

### 分类模型
预处理：文本-->信息
分类模型：信息-->知识， 特征抽取器
文本分类任务最主要的是抓住找到文本的关键信息，即找到关键词特征
|CNN|可以提取一些关键词特征，短距离的依赖关系，配合maxpooling提取文本的主要特征，捕捉局部相关性，具体到文本分类任务中可以利用CNN来提取句子中类似 n-gram 的关键信息|
|maxpooling|提取最主要的特征很强，但是会忽略到很细微的特征|
|attention|短文本上差于max-pooling，但是在长文本上要好，主要是attention会将一部分小的特征也包含进来|
|capsule||
|lstm|捕获变长且双向的的 "n-gram" 信息|
短文本：文本段，长依赖少，关键词容易提取，所以用CNN+MAX-Pooling就可以取得不错的结果。用LSTM+Capsule 提取关键词特征，
长文要用LSTM,不能直接使用CNN
bert在短文本的上的效果没有长文本上的好，因为短文本需要语义小，主要靠关键词
### 后处理(模型融合)


### 训练策略
- fine-tuning: embedding 一开始不加学习率(或者很低)，慢慢的提高一点，但是也很小
- 循环学习率（这个base max step 调的好，能巨大加速收敛速度）

### 文本分类任务的特征工程
- 文本预处理，中文：文本分词(词的表示好于字符，因为提取关键词)，去停用词
文本表示：将原始文本表示为数的形式，计算机可读语言
- 词袋模型：高纬度、高稀疏性
- 向量空间模型
特征提取
词袋模型
TF-IDF
互信息
卡方
频率
多类问题特征选择
不同特征选择方法比较
特征选择实例

### 模型评价

### 模型选择


### tricks
- 关注迭代质量：为什么要实验？结论是什么？下一步怎么实验？
- embedding 后使用dropout
- 显然问题fasttext，简单问题CNN，复杂问题RNN，终极问题bert
- ensemble
- 尽可能找到还原语义的pretrained embedding，实际情况是oov千奇百怪，拼写检查，基本上是100倍的努力，一点点收益，或者拆词，拆字能一定程度上缓解
- 要用CNN的话，用空洞版本
- 确保分词器与词向量表中的token粒度match其实是更更重要的事情！


### 超参调节
[介绍 1](https://zhuanlan.zhihu.com/p/24720954?utm_source=zhihu&utm_medium=social)


### 类别不均衡问题的解决方案
[微信文章](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484993&idx=1&sn=0bd32089a638e5a1b48239656febb6e0&chksm=970c2e97a07ba7818d63dddbb469486dccb369ecc11f38ffdea596452b9e5bf65772820a8ac9&token=407616831&lang=zh_CN#rd)
[知乎问题严重数据倾斜文本分类，比如正反比1:20～100，适合什么model，查准一般要做到多少可以上线？](https://www.zhihu.com/question/59236897)
